{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced benchmark analysis...\n",
      "Performing feature selection analysis...\n",
      "Processing feature combination: ('DIX',)\n",
      "  Training ARIMA...\n",
      "    ARIMA completed - R2: 0.379\n",
      "  Training GARCH...\n",
      "    GARCH completed - R2: -3.510\n",
      "  Training ANN...\n",
      "    Grid search 1/6 for ANN\n",
      "    Grid search 2/6 for ANN\n",
      "    Grid search 3/6 for ANN\n",
      "    Grid search 4/6 for ANN\n",
      "    Grid search 5/6 for ANN\n",
      "    Grid search 6/6 for ANN\n",
      "SHAP: Input shape (617, 10, 1), Features: 1\n",
      "SHAP: Flattened to (10, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c688a935082644d0bdf05a5dad8c7a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP: Success! Importance shape: (1,)\n",
      "    ANN completed - R2: -2.888\n",
      "  Training RNN...\n",
      "Skipping SHAP analysis for RNN (too complex or insufficient data)\n",
      "    RNN completed - R2: -0.316\n",
      "  Training LSTM...\n",
      "    Grid search 1/6 for LSTM\n",
      "    Grid search 2/6 for LSTM\n",
      "    Grid search 3/6 for LSTM\n",
      "    Grid search 4/6 for LSTM\n",
      "    Grid search 5/6 for LSTM\n",
      "    Grid search 6/6 for LSTM\n",
      "Skipping SHAP analysis for LSTM (too complex or insufficient data)\n",
      "    LSTM completed - R2: -0.192\n",
      "  Training GRU...\n",
      "Error training GRU: cannot insert level_0, already exists\n",
      "  Training CNN...\n",
      "Error training CNN: cannot insert level_0, already exists\n",
      "  Training CNN_LSTM...\n",
      "Error training CNN_LSTM: cannot insert level_0, already exists\n",
      "  Training CapsNet...\n",
      "Error training CapsNet: cannot insert level_0, already exists\n",
      "  Training Lightweight_ANN...\n",
      "Error training Lightweight_ANN: cannot insert level_0, already exists\n",
      "  Training Lightweight_LSTM...\n",
      "Error training Lightweight_LSTM: cannot insert level_0, already exists\n",
      "  Training Lightweight_CNN_LSTM...\n",
      "Error training Lightweight_CNN_LSTM: cannot insert level_0, already exists\n",
      "  Training ARIMA...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pywt\n",
    "import itertools\n",
    "import nolds\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Dense, LSTM, GRU, SimpleRNN, Conv1D,\n",
    "                                     MaxPooling1D, Flatten, Input, Reshape,\n",
    "                                     Lambda, concatenate, TimeDistributed, Dropout)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, \n",
    "                             r2_score, explained_variance_score)\n",
    "from sklearn.model_selection import TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "\n",
    "# Interpretability libraries\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 0. Setup directories\n",
    "# ------------------------------------------------\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('interpretability', exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Enhanced Parameter grids for hyperparameter search\n",
    "# ------------------------------------------------\n",
    "param_grid = {\n",
    "    'ANN': {\n",
    "        'layers': [[128,64,32], [64,32], [256,128,64]],\n",
    "        'learning_rate': [1e-3, 1e-4, 5e-4],\n",
    "        'batch_size': [32, 64],\n",
    "        'dropout_rate': [0.2, 0.3]\n",
    "    },\n",
    "    'LSTM': {\n",
    "        'units': [[128,64], [64,32], [256,128]],\n",
    "        'learning_rate': [1e-3, 1e-4],\n",
    "        'batch_size': [32, 64],\n",
    "        'dropout_rate': [0.2, 0.3]\n",
    "    },\n",
    "    'CNN_LSTM': {\n",
    "        'conv_filters': [32, 64, 128],\n",
    "        'lstm_units': [64, 128],\n",
    "        'learning_rate': [1e-3, 1e-4],\n",
    "        'batch_size': [32, 64]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Load Data with Market Regime Detection\n",
    "# ------------------------------------------------\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path, parse_dates=['DATE'])\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Enhanced Market Regimes with Bull/Bear Detection\n",
    "# ------------------------------------------------\n",
    "market_periods = {\n",
    "    'bull_2012': ('2012-10-05','2015-12-31'),\n",
    "    'correction_2016': ('2016-01-01','2016-06-30'),\n",
    "    'bull_2016': ('2016-07-01','2018-01-25'),\n",
    "    'bear_2018': ('2018-01-26','2018-12-24'),\n",
    "    'recovery_2019': ('2018-12-25','2020-02-19'),\n",
    "    'covid_crash': ('2020-02-20','2020-03-23'),\n",
    "    'recovery_2020': ('2020-03-24','2022-01-03'),\n",
    "    'bear_2022': ('2022-01-04','2022-10-12'),\n",
    "    'bull_2022': ('2022-10-13','2025-03-27')\n",
    "}\n",
    "\n",
    "def label_market_regime(date):\n",
    "    if isinstance(date, (int, float)):\n",
    "        date = pd.to_datetime(date, unit='ns' if date > 1e15 else 's')\n",
    "    elif not hasattr(date, 'strftime'):\n",
    "        date = pd.to_datetime(date)\n",
    "    \n",
    "    ds = date.strftime('%Y-%m-%d')\n",
    "    for regime, (start, end) in market_periods.items():\n",
    "        if start <= ds <= end:\n",
    "            return regime\n",
    "    return 'other'\n",
    "\n",
    "def categorize_regime_type(regime):\n",
    "    \"\"\"Categorize detailed regimes into bull/bear/neutral\"\"\"\n",
    "    if 'bull' in regime or 'recovery' in regime:\n",
    "        return 'bull'\n",
    "    elif 'bear' in regime or 'crash' in regime:\n",
    "        return 'bear'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Enhanced Feature Selection with RFE and SHAP (CORREGIDO)\n",
    "# ------------------------------------------------\n",
    "def recursive_feature_elimination(X, y, feature_names, n_features=10):\n",
    "    \"\"\"Apply RFE with Random Forest for feature selection\"\"\"\n",
    "    try:\n",
    "        rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rfe = RFECV(rf, step=1, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        \n",
    "        # Reshape for 2D if needed\n",
    "        if X.ndim == 3:\n",
    "            X_2d = X.reshape(X.shape[0], -1)\n",
    "        else:\n",
    "            X_2d = X\n",
    "        \n",
    "        rfe.fit(X_2d, y)\n",
    "        \n",
    "        selected_features = [feature_names[i] for i in range(len(feature_names)) if rfe.support_[i]]\n",
    "        feature_rankings = rfe.ranking_\n",
    "        \n",
    "        # CORREGIDO: usar cv_results_ en lugar de grid_scores_\n",
    "        cv_scores = rfe.cv_results_['mean_test_score'] if hasattr(rfe, 'cv_results_') else [0.5]\n",
    "        \n",
    "        return selected_features, feature_rankings, cv_scores\n",
    "    except Exception as e:\n",
    "        print(f\"RFE failed: {e}\")\n",
    "        return feature_names[:min(n_features, len(feature_names))], list(range(len(feature_names))), [0.5]\n",
    "\n",
    "def calculate_feature_importance_shap(model, X_sample, feature_names):\n",
    "    \"\"\"Calculate SHAP values for feature importance - ULTRA FIXED\"\"\"\n",
    "    try:\n",
    "        print(f\"SHAP: Input shape {X_sample.shape}, Features: {len(feature_names)}\")\n",
    "        \n",
    "        # Validación básica\n",
    "        if len(X_sample) == 0 or len(feature_names) == 0:\n",
    "            print(\"SHAP: Empty input data\")\n",
    "            return None, None\n",
    "            \n",
    "        # Tomar muestra pequeña para evitar problemas\n",
    "        sample_size = min(10, len(X_sample))  # Muy pequeño\n",
    "        X_shap = X_sample[:sample_size]\n",
    "        \n",
    "        # CRÍTICO: Aplanar para modelos de secuencia\n",
    "        if X_sample.ndim == 3:\n",
    "            # (samples, timesteps, features) -> (samples, timesteps*features)\n",
    "            X_flat = X_shap.reshape(X_shap.shape[0], -1)\n",
    "            print(f\"SHAP: Flattened to {X_flat.shape}\")\n",
    "        else:\n",
    "            X_flat = X_shap\n",
    "            \n",
    "        # Crear predictor compatible\n",
    "        def safe_predict(x):\n",
    "            try:\n",
    "                # Asegurar forma correcta para el modelo\n",
    "                if x.ndim == 2 and X_sample.ndim == 3:\n",
    "                    # Reshape back to original input shape\n",
    "                    n_samples = x.shape[0]\n",
    "                    x_reshaped = x.reshape(n_samples, X_sample.shape[1], X_sample.shape[2])\n",
    "                    pred = model.predict(x_reshaped, verbose=0)\n",
    "                else:\n",
    "                    pred = model.predict(x, verbose=0)\n",
    "                \n",
    "                return pred.flatten() if pred.ndim > 1 else pred\n",
    "            except Exception as e:\n",
    "                print(f\"SHAP predictor error: {e}\")\n",
    "                # Fallback: return zeros\n",
    "                return np.zeros(x.shape[0])\n",
    "        \n",
    "        # Usar explicador más simple\n",
    "        try:\n",
    "            # Background muy pequeño\n",
    "            background = X_flat[:2]  # Solo 2 muestras\n",
    "            explainer = shap.KernelExplainer(safe_predict, background, link=\"identity\")\n",
    "            \n",
    "            # Analizar solo 3 muestras\n",
    "            shap_values = explainer.shap_values(X_flat[:3], nsamples=50)  # Muy pocos samples\n",
    "            \n",
    "            if shap_values is None:\n",
    "                return None, None\n",
    "                \n",
    "            # Procesar resultados\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[0]\n",
    "                \n",
    "            # Calcular importancia promedio\n",
    "            importance_scores = np.mean(np.abs(shap_values), axis=0)\n",
    "            \n",
    "            # Ajustar a número de features si es necesario\n",
    "            if len(importance_scores) > len(feature_names):\n",
    "                importance_scores = importance_scores[:len(feature_names)]\n",
    "            elif len(importance_scores) < len(feature_names):\n",
    "                # Pad with zeros\n",
    "                padding = np.zeros(len(feature_names) - len(importance_scores))\n",
    "                importance_scores = np.concatenate([importance_scores, padding])\n",
    "                \n",
    "            print(f\"SHAP: Success! Importance shape: {importance_scores.shape}\")\n",
    "            return importance_scores, shap_values\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SHAP KernelExplainer failed: {e}\")\n",
    "            return None, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP calculation completely failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def visualize_feature_importance(importance_scores, feature_names, title=\"Feature Importance\"):\n",
    "    \"\"\"Create feature importance visualizations - SAFE VERSION\"\"\"\n",
    "    try:\n",
    "        if importance_scores is None or len(importance_scores) == 0:\n",
    "            print(f\"No importance scores available for {title}\")\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Bar plot\n",
    "        plt.subplot(2, 1, 1)\n",
    "        indices = np.argsort(importance_scores)[::-1]\n",
    "        plt.bar(range(len(importance_scores)), importance_scores[indices])\n",
    "        plt.xticks(range(len(importance_scores)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.title(f\"{title} - Bar Plot\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Heatmap\n",
    "        plt.subplot(2, 1, 2)\n",
    "        importance_matrix = importance_scores.reshape(1, -1)\n",
    "        sns.heatmap(importance_matrix, xticklabels=feature_names, yticklabels=['Importance'], \n",
    "                    annot=True, cmap='viridis', fmt='.3f')\n",
    "        plt.title(f\"{title} - Heatmap\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'interpretability/{title.lower().replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization failed for {title}: {e}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Computational Efficiency Measurements (MEJORADO)\n",
    "# ------------------------------------------------\n",
    "class ModelLatencyProfiler:\n",
    "    def __init__(self):\n",
    "        self.latency_results = []\n",
    "    \n",
    "    def measure_inference_time(self, model, X_test, model_name, n_runs=50):  # Reducido de 100 a 50\n",
    "        \"\"\"Measure inference latency for a model\"\"\"\n",
    "        try:\n",
    "            # Warm up\n",
    "            _ = model.predict(X_test[:5], verbose=0)\n",
    "            \n",
    "            # Measure latency\n",
    "            times = []\n",
    "            for _ in range(n_runs):\n",
    "                start_time = time.time()\n",
    "                _ = model.predict(X_test[:1], verbose=0)  # Single prediction\n",
    "                end_time = time.time()\n",
    "                times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "            \n",
    "            latency_stats = {\n",
    "                'model': model_name,\n",
    "                'mean_latency_ms': np.mean(times),\n",
    "                'std_latency_ms': np.std(times),\n",
    "                'min_latency_ms': np.min(times),\n",
    "                'max_latency_ms': np.max(times),\n",
    "                'p95_latency_ms': np.percentile(times, 95),\n",
    "                'p99_latency_ms': np.percentile(times, 99)\n",
    "            }\n",
    "            \n",
    "            self.latency_results.append(latency_stats)\n",
    "            return latency_stats\n",
    "        except Exception as e:\n",
    "            print(f\"Latency measurement failed for {model_name}: {e}\")\n",
    "            return {\n",
    "                'model': model_name,\n",
    "                'mean_latency_ms': 0,\n",
    "                'std_latency_ms': 0,\n",
    "                'min_latency_ms': 0,\n",
    "                'max_latency_ms': 0,\n",
    "                'p95_latency_ms': 0,\n",
    "                'p99_latency_ms': 0\n",
    "            }\n",
    "    \n",
    "    def compare_model_efficiency(self):\n",
    "        \"\"\"Create comparison plots for model efficiency\"\"\"\n",
    "        try:\n",
    "            if not self.latency_results:\n",
    "                print(\"No latency results to compare\")\n",
    "                return\n",
    "            \n",
    "            df = pd.DataFrame(self.latency_results)\n",
    "            \n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Latency comparison\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.bar(df['model'], df['mean_latency_ms'], yerr=df['std_latency_ms'])\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('Latency (ms)')\n",
    "            plt.title('Model Inference Latency Comparison')\n",
    "            \n",
    "            # Box plot for latency distribution\n",
    "            plt.subplot(2, 2, 2)\n",
    "            latency_data = []\n",
    "            model_names = []\n",
    "            for result in self.latency_results:\n",
    "                latency_data.append([result['mean_latency_ms']])\n",
    "                model_names.append(result['model'])\n",
    "            \n",
    "            if latency_data:\n",
    "                plt.boxplot(latency_data, labels=model_names)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.ylabel('Latency (ms)')\n",
    "                plt.title('Latency Distribution by Model')\n",
    "            \n",
    "            # P95 vs P99 comparison\n",
    "            plt.subplot(2, 2, 3)\n",
    "            x = np.arange(len(df))\n",
    "            width = 0.35\n",
    "            plt.bar(x - width/2, df['p95_latency_ms'], width, label='P95')\n",
    "            plt.bar(x + width/2, df['p99_latency_ms'], width, label='P99')\n",
    "            plt.xticks(x, df['model'], rotation=45)\n",
    "            plt.ylabel('Latency (ms)')\n",
    "            plt.title('P95 vs P99 Latency')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Efficiency score (1/latency)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            efficiency_score = 1000 / (df['mean_latency_ms'] + 1e-6)  # Avoid division by zero\n",
    "            plt.bar(df['model'], efficiency_score)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('Efficiency Score')\n",
    "            plt.title('Model Efficiency Score (Higher = Better)')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('plots/model_efficiency_comparison.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Efficiency comparison failed: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5. Lightweight Model Alternatives\n",
    "# ------------------------------------------------\n",
    "def create_lightweight_model(model_type, input_shape, compression_ratio=0.5):\n",
    "    \"\"\"Create lightweight versions of models using pruning concepts\"\"\"\n",
    "    \n",
    "    if model_type == 'Lightweight_CNN_LSTM':\n",
    "        model = Sequential([\n",
    "            Conv1D(32, 3, activation='relu', input_shape=input_shape),  # Reduced filters\n",
    "            MaxPooling1D(2),\n",
    "            LSTM(32, return_sequences=False, dropout=0.2),  # Reduced units\n",
    "            Dense(16, activation='relu'),  # Smaller dense layer\n",
    "            Dense(1)\n",
    "        ])\n",
    "    \n",
    "    elif model_type == 'Lightweight_LSTM':\n",
    "        units = int(64 * compression_ratio)\n",
    "        model = Sequential([\n",
    "            LSTM(units, return_sequences=True, input_shape=input_shape, dropout=0.2),\n",
    "            LSTM(units//2, dropout=0.2),\n",
    "            Dense(units//4, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    \n",
    "    elif model_type == 'Lightweight_ANN':\n",
    "        model = Sequential([\n",
    "            Flatten(input_shape=input_shape),\n",
    "            Dense(64, activation='relu'),  # Much smaller\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "def knowledge_distillation_training(teacher_model, student_model, X_train, y_train, \n",
    "                                   X_val, y_val, temperature=3.0, alpha=0.7):\n",
    "    \"\"\"Implement knowledge distillation for model compression\"\"\"\n",
    "    \n",
    "    def distillation_loss(y_true, y_pred, teacher_pred, temperature, alpha):\n",
    "        \"\"\"Custom loss function for knowledge distillation\"\"\"\n",
    "        # Student loss (hard targets)\n",
    "        student_loss = tf.keras.losses.mse(y_true, y_pred)\n",
    "        \n",
    "        # Distillation loss (soft targets)\n",
    "        teacher_soft = teacher_pred / temperature\n",
    "        student_soft = y_pred / temperature\n",
    "        distill_loss = tf.keras.losses.mse(teacher_soft, student_soft) * (temperature ** 2)\n",
    "        \n",
    "        # Combined loss\n",
    "        return alpha * distill_loss + (1 - alpha) * student_loss\n",
    "    \n",
    "    # Get teacher predictions\n",
    "    teacher_pred_train = teacher_model.predict(X_train)\n",
    "    teacher_pred_val = teacher_model.predict(X_val)\n",
    "    \n",
    "    # Custom training loop would go here\n",
    "    # For simplicity, using regular training with teacher predictions as additional guidance\n",
    "    \n",
    "    # Train student model\n",
    "    history = student_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[EarlyStopping(patience=10)],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return student_model, history\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6. Online Learning and Concept Drift Detection\n",
    "# ------------------------------------------------\n",
    "class OnlineLearningAdapter:\n",
    "    def __init__(self, base_model, learning_rate=0.01, window_size=100):\n",
    "        self.base_model = base_model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.window_size = window_size\n",
    "        self.performance_history = []\n",
    "        self.drift_detected = False\n",
    "    \n",
    "    def detect_concept_drift(self, current_loss, threshold=2.0):\n",
    "        \"\"\"Simple concept drift detection based on performance degradation\"\"\"\n",
    "        if len(self.performance_history) < self.window_size:\n",
    "            self.performance_history.append(current_loss)\n",
    "            return False\n",
    "        \n",
    "        recent_avg = np.mean(self.performance_history[-self.window_size//2:])\n",
    "        historical_avg = np.mean(self.performance_history[:-self.window_size//2])\n",
    "        \n",
    "        if recent_avg > historical_avg * threshold:\n",
    "            self.drift_detected = True\n",
    "            return True\n",
    "        \n",
    "        self.performance_history.append(current_loss)\n",
    "        if len(self.performance_history) > self.window_size * 2:\n",
    "            self.performance_history = self.performance_history[-self.window_size:]\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def incremental_update(self, X_new, y_new):\n",
    "        \"\"\"Perform incremental learning on new data\"\"\"\n",
    "        if self.drift_detected:\n",
    "            # Retrain with higher learning rate if drift detected\n",
    "            self.base_model.compile(\n",
    "                optimizer=Adam(learning_rate=self.learning_rate * 2),\n",
    "                loss='mse'\n",
    "            )\n",
    "            self.drift_detected = False\n",
    "        \n",
    "        # Incremental training\n",
    "        self.base_model.fit(X_new, y_new, epochs=1, verbose=0)\n",
    "        \n",
    "        # Update performance tracking\n",
    "        loss = self.base_model.evaluate(X_new, y_new, verbose=0)\n",
    "        self.detect_concept_drift(loss)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 7. Enhanced Interpretability Framework (CORREGIDO)\n",
    "# ------------------------------------------------\n",
    "class InterpretabilityFramework:\n",
    "    def __init__(self, model, feature_names):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.explanations = {}\n",
    "    \n",
    "    def explain_with_lime(self, X_sample, y_sample, idx=0):\n",
    "        \"\"\"Generate LIME explanations for specific predictions\"\"\"\n",
    "        try:\n",
    "            # Flatten input for LIME if needed\n",
    "            if X_sample.ndim == 3:\n",
    "                X_flat = X_sample.reshape(X_sample.shape[0], -1)\n",
    "                feature_names_flat = [f\"{name}_{i}\" for name in self.feature_names \n",
    "                                    for i in range(X_sample.shape[1])]\n",
    "            else:\n",
    "                X_flat = X_sample\n",
    "                feature_names_flat = self.feature_names\n",
    "            \n",
    "            # Create LIME explainer\n",
    "            explainer = LimeTabularExplainer(\n",
    "                X_flat,\n",
    "                feature_names=feature_names_flat,\n",
    "                mode='regression'\n",
    "            )\n",
    "            \n",
    "            # Explain specific instance\n",
    "            explanation = explainer.explain_instance(\n",
    "                X_flat[idx], \n",
    "                lambda x: self.model.predict(x.reshape(-1, *X_sample.shape[1:]), verbose=0),\n",
    "                num_features=min(10, len(feature_names_flat))\n",
    "            )\n",
    "            \n",
    "            self.explanations[f'lime_{idx}'] = explanation\n",
    "            return explanation\n",
    "        except Exception as e:\n",
    "            print(f\"LIME explanation failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def explain_with_shap(self, X_sample):\n",
    "        \"\"\"Generate SHAP explanations - FIXED\"\"\"\n",
    "        try:\n",
    "            # Ensure we have enough samples\n",
    "            if len(X_sample) < 10:\n",
    "                print(\"Not enough samples for SHAP analysis\")\n",
    "                return None\n",
    "                \n",
    "            sample_size = min(30, len(X_sample))\n",
    "            X_shap = X_sample[:sample_size]\n",
    "            \n",
    "            # For Keras models, use KernelExplainer for stability\n",
    "            if hasattr(self.model, 'predict'):\n",
    "                def model_predict(x):\n",
    "                    return self.model.predict(x, verbose=0).flatten()\n",
    "                \n",
    "                background = X_shap[:5]  # Small background set\n",
    "                explainer = shap.KernelExplainer(model_predict, background)\n",
    "                shap_values = explainer.shap_values(X_shap[:10])  # Small analysis set\n",
    "            else:\n",
    "                # Fallback to basic explainer\n",
    "                explainer = shap.Explainer(self.model, X_shap[:5])\n",
    "                shap_values = explainer(X_shap[:10])\n",
    "            \n",
    "            self.explanations['shap'] = shap_values\n",
    "            return shap_values\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SHAP explanation failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_interpretability_report(self, X_sample, y_sample, save_path='interpretability/'):\n",
    "        \"\"\"Generate comprehensive interpretability report\"\"\"\n",
    "        try:\n",
    "            # SHAP analysis\n",
    "            shap_values = self.explain_with_shap(X_sample)\n",
    "            if shap_values is not None:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    shap.summary_plot(shap_values.values, X_sample[:10], \n",
    "                                    feature_names=self.feature_names, \n",
    "                                    show=False)\n",
    "                else:\n",
    "                    shap.summary_plot(shap_values, X_sample[:10], \n",
    "                                    feature_names=self.feature_names, \n",
    "                                    show=False)\n",
    "                plt.savefig(f'{save_path}shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            # LIME analysis for sample predictions\n",
    "            for i in [0, len(X_sample)//2, -1]:\n",
    "                if i >= len(X_sample) or i < 0:\n",
    "                    continue\n",
    "                explanation = self.explain_with_lime(X_sample, y_sample, i)\n",
    "                if explanation:\n",
    "                    fig = explanation.as_pyplot_figure()\n",
    "                    fig.savefig(f'{save_path}lime_explanation_{i}.png', dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Interpretability report failed: {e}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 8. Market Shock Case Studies\n",
    "# ------------------------------------------------\n",
    "def analyze_market_shock_scenarios(pred_df):\n",
    "    \"\"\"Analyze model performance during market shock periods\"\"\"\n",
    "    \n",
    "    shock_periods = {\n",
    "        'COVID_Crash': ('2020-02-20', '2020-03-23'),\n",
    "        'Bear_2018': ('2018-01-26', '2018-12-24'),\n",
    "        'Bear_2022': ('2022-01-04', '2022-10-12')\n",
    "    }\n",
    "    \n",
    "    shock_analysis = []\n",
    "    \n",
    "    for shock_name, (start, end) in shock_periods.items():\n",
    "        # Filter predictions for shock period\n",
    "        mask = (pred_df['time_index'] >= start) & (pred_df['time_index'] <= end)\n",
    "        shock_data = pred_df[mask]\n",
    "        \n",
    "        if len(shock_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics during shock\n",
    "        for model in shock_data['model'].unique():\n",
    "            model_data = shock_data[shock_data['model'] == model]\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            metrics = calculate_metrics(model_data['y_true'], model_data['y_pred'])\n",
    "            \n",
    "            shock_analysis.append({\n",
    "                'shock_period': shock_name,\n",
    "                'model': model,\n",
    "                'start_date': start,\n",
    "                'end_date': end,\n",
    "                'n_observations': len(model_data),\n",
    "                **metrics\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(shock_analysis)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 9. Enhanced Fractal and Wavelet Analysis\n",
    "# ------------------------------------------------\n",
    "def hurst_exponent(ts):\n",
    "    try:\n",
    "        lags = range(2, min(20, len(ts)//4))\n",
    "        tau = [np.std(ts[lag:] - ts[:-lag]) for lag in lags if lag < len(ts)]\n",
    "        if len(tau) < 3:\n",
    "            return np.nan\n",
    "        \n",
    "        log_lags = np.log([lag for lag in lags if lag < len(ts)][:len(tau)])\n",
    "        log_tau = np.log(tau)\n",
    "        \n",
    "        # Remove any invalid values\n",
    "        valid_mask = np.isfinite(log_lags) & np.isfinite(log_tau)\n",
    "        if np.sum(valid_mask) < 3:\n",
    "            return np.nan\n",
    "        \n",
    "        poly = np.polyfit(log_lags[valid_mask], log_tau[valid_mask], 1)\n",
    "        return poly[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def apply_hurst(df, price_col='PRICE', window_size=100):\n",
    "    df['HURST_PRICE'] = df[price_col].rolling(window=window_size).apply(hurst_exponent, raw=True)\n",
    "    return df\n",
    "\n",
    "def apply_wavelet_energy(segment, wavelet='db4', level=3):\n",
    "    try:\n",
    "        if len(segment) < 2**level:\n",
    "            return [np.nan] * (level + 1)\n",
    "        coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "        return [np.sum(c**2) if len(c) > 0 else 0 for c in coeffs]\n",
    "    except:\n",
    "        return [np.nan] * (level + 1)\n",
    "\n",
    "def apply_wavelets(df, col_list=None, window=150):\n",
    "    if col_list is None:\n",
    "        col_list = ['PRICE', 'PUTCALLRATIO']\n",
    "    wavelet_cols = []\n",
    "    for col in col_list:\n",
    "        feats = []\n",
    "        for i in range(window, len(df)):\n",
    "            segment = df[col].iloc[i-window:i].dropna()\n",
    "            if len(segment) >= window//2:\n",
    "                energy_vals = apply_wavelet_energy(segment)\n",
    "            else:\n",
    "                energy_vals = [np.nan] * 4\n",
    "            feats.append(energy_vals)\n",
    "        \n",
    "        for j in range(4):\n",
    "            new_col = f'WAVELET_{col}_L{j}'\n",
    "            df[new_col] = [np.nan]*window + [x[j] for x in feats]\n",
    "            wavelet_cols.append(new_col)\n",
    "    return df, wavelet_cols\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 10. Enhanced Feature Preparation\n",
    "# ------------------------------------------------\n",
    "def prepare_features(df, features, target='VIX', lookback=10, scale_method='MinMax'):\n",
    "    df_clean = df.dropna(subset=features+[target]).copy()\n",
    "    df_clean['regime'] = df_clean.index.to_series().apply(label_market_regime)\n",
    "    df_clean['regime_type'] = df_clean['regime'].apply(categorize_regime_type)\n",
    "    \n",
    "    if len(df_clean) <= lookback:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    scaler = StandardScaler() if scale_method=='Standard' else MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df_clean[features + [target]])\n",
    "    \n",
    "    X, y, idx, regimes = [], [], [], []\n",
    "    for i in range(lookback, len(scaled)):\n",
    "        X.append(scaled[i-lookback:i, :-1])\n",
    "        y.append(scaled[i, -1])\n",
    "        idx.append(df_clean.index[i])\n",
    "        regimes.append(df_clean['regime_type'].iloc[i])\n",
    "    \n",
    "    return np.array(X), np.array(y), idx, scaler, regimes\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 11. Statistical Baselines: Enhanced ARIMA & GARCH (CORREGIDO)\n",
    "# ------------------------------------------------\n",
    "def train_arima_baseline(y_series, max_p=3, max_d=2, max_q=3):\n",
    "    \"\"\"Enhanced ARIMA with automatic order selection - FIXED\"\"\"\n",
    "    try:\n",
    "        # Asegurar que y_series es una Serie válida sin NaN\n",
    "        y_clean = y_series.dropna()\n",
    "        if len(y_clean) < 10:\n",
    "            print(\"Not enough data for ARIMA training\")\n",
    "            return None\n",
    "            \n",
    "        best_aic = np.inf\n",
    "        best_model = None\n",
    "        best_order = None\n",
    "        \n",
    "        for p in range(max_p + 1):\n",
    "            for d in range(max_d + 1):\n",
    "                for q in range(max_q + 1):\n",
    "                    try:\n",
    "                        model = ARIMA(y_clean, order=(p,d,q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic:\n",
    "                            best_aic = fitted_model.aic\n",
    "                            best_model = fitted_model\n",
    "                            best_order = (p,d,q)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        if best_model is None:\n",
    "            # Fallback to simple model\n",
    "            model = ARIMA(y_clean, order=(1,0,1))\n",
    "            best_model = model.fit()\n",
    "            \n",
    "        return best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_garch_baseline(y_series, max_p=2, max_q=2):\n",
    "    \"\"\"Enhanced GARCH with automatic order selection - FIXED\"\"\"\n",
    "    try:\n",
    "        # Asegurar que y_series es una Serie válida\n",
    "        y_clean = y_series.dropna()\n",
    "        if len(y_clean) < 20:\n",
    "            print(\"Not enough data for GARCH training\")\n",
    "            return None\n",
    "            \n",
    "        # Convertir a returns si es necesario\n",
    "        returns = y_clean.pct_change().dropna() * 100  # Percentage returns\n",
    "        \n",
    "        if len(returns) < 10:\n",
    "            print(\"Not enough returns for GARCH\")\n",
    "            return None\n",
    "            \n",
    "        best_aic = np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        for p in range(1, max_p + 1):\n",
    "            for q in range(1, max_q + 1):\n",
    "                try:\n",
    "                    model = arch_model(returns, vol='Garch', p=p, q=q, dist='normal')\n",
    "                    fitted_model = model.fit(disp='off')\n",
    "                    if fitted_model.aic < best_aic:\n",
    "                        best_aic = fitted_model.aic\n",
    "                        best_model = fitted_model\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if best_model is None:\n",
    "            # Fallback to simple GARCH(1,1)\n",
    "            model = arch_model(returns, vol='Garch', p=1, q=1, dist='normal')\n",
    "            best_model = model.fit(disp='off')\n",
    "            \n",
    "        return best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GARCH training failed: {e}\")\n",
    "        return None\n",
    "# ------------------------------------------------\n",
    "# 12. Enhanced Model Architecture\n",
    "# ------------------------------------------------\n",
    "def squash(vectors, axis=-1):\n",
    "    s2n = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s2n / (1 + s2n) / tf.sqrt(s2n + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "def build_capsule_model(input_shape, num_capsule=10, dim_capsule=16):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(128,3,activation='relu',padding='same')(inputs)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(256,3,activation='relu',padding='same')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Reshape((-1,dim_capsule))(x)\n",
    "    x = Lambda(squash)(x)\n",
    "    caps = [Lambda(squash)(TimeDistributed(Dense(dim_capsule))(x)) for _ in range(num_capsule)]\n",
    "    net = concatenate(caps,axis=-1)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(64,activation='relu')(net)\n",
    "    net = Dense(32,activation='relu')(net)\n",
    "    out = Dense(1)(net)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(), loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_model(model_type, input_shape, layers=None, lr=1e-3, dropout_rate=0.2):\n",
    "    if model_type=='CapsNet':\n",
    "        return build_capsule_model(input_shape)\n",
    "    elif model_type.startswith('Lightweight_'):\n",
    "        return create_lightweight_model(model_type, input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    if layers is None:\n",
    "        configs = {\n",
    "            'ANN': [128,64,32],\n",
    "            'RNN': [128,64], 'LSTM': [128,64], 'GRU': [128,64],\n",
    "            'CNN': [128,64], 'CNN_LSTM': [64,128,64]\n",
    "        }\n",
    "        layers = configs.get(model_type, [64,32])\n",
    "    \n",
    "    if model_type=='ANN':\n",
    "        model.add(Input(shape=input_shape))\n",
    "        model.add(Flatten())\n",
    "        for units in layers:\n",
    "            model.add(Dense(units,activation='relu'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "    elif model_type in ['RNN','LSTM','GRU']:\n",
    "        LayerClass = {'RNN': SimpleRNN,'LSTM':LSTM,'GRU':GRU}[model_type]\n",
    "        model.add(LayerClass(layers[0],return_sequences=True,input_shape=input_shape,dropout=dropout_rate))\n",
    "        if len(layers) > 1:\n",
    "            model.add(LayerClass(layers[1],dropout=dropout_rate))\n",
    "        else:\n",
    "            model.add(LayerClass(64,dropout=dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "    elif model_type=='CNN':\n",
    "        model.add(Conv1D(layers[0],3,activation='relu',input_shape=input_shape))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Conv1D(layers[1] if len(layers)>1 else 64,3,activation='relu'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "    elif model_type=='CNN_LSTM':\n",
    "        model.add(Conv1D(layers[0] if len(layers)>0 else 64,3,activation='relu',input_shape=input_shape))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(LSTM(layers[1] if len(layers)>1 else 128,return_sequences=True,dropout=dropout_rate))\n",
    "        model.add(LSTM(layers[2] if len(layers)>2 else 64,dropout=dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 13. Enhanced Metrics & Statistical Tests\n",
    "# ------------------------------------------------\n",
    "def calculate_metrics(y_true,y_pred):\n",
    "    return {\n",
    "        'mse': mean_squared_error(y_true,y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true,y_pred)),\n",
    "        'mae': mean_absolute_error(y_true,y_pred),\n",
    "        'r2': r2_score(y_true,y_pred),\n",
    "        'explained_variance': explained_variance_score(y_true,y_pred),\n",
    "        'mape': np.mean(np.abs((y_true-y_pred)/(y_true+1e-8)))*100\n",
    "    }\n",
    "\n",
    "def diebold_mariano_test(y_true,y_pred1,y_pred2,crit='MSE'):\n",
    "    e1,e2=y_true-y_pred1,y_true-y_pred2\n",
    "    d=(e1**2)-(e2**2)\n",
    "    DM=d.mean()/np.sqrt(d.var(ddof=1)/len(d))\n",
    "    p=2*(1-0.5*(1+tf.math.erf(abs(DM)/tf.sqrt(2.0))))\n",
    "    return DM,p\n",
    "\n",
    "def compare_models_dm(pred_df, group_by_cols):\n",
    "    \"\"\"Enhanced DM test with regime-specific analysis\"\"\"\n",
    "    dm_results = []\n",
    "    \n",
    "    for group_vals, group_data in pred_df.groupby(group_by_cols):\n",
    "        models = group_data['model'].unique()\n",
    "        \n",
    "        for i, model1 in enumerate(models):\n",
    "            for model2 in models[i+1:]:\n",
    "                data1 = group_data[group_data['model'] == model1]\n",
    "                data2 = group_data[group_data['model'] == model2]\n",
    "                \n",
    "                common_idx = set(data1['time_index']).intersection(set(data2['time_index']))\n",
    "                if len(common_idx) < 10:  # Minimum sample size\n",
    "                    continue\n",
    "                    \n",
    "                data1_aligned = data1[data1['time_index'].isin(common_idx)].sort_values('time_index')\n",
    "                data2_aligned = data2[data2['time_index'].isin(common_idx)].sort_values('time_index')\n",
    "                \n",
    "                if len(data1_aligned) != len(data2_aligned):\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    dm_stat, p_val = diebold_mariano_test(\n",
    "                        data1_aligned['y_true'].values,\n",
    "                        data1_aligned['y_pred'].values,\n",
    "                        data2_aligned['y_pred'].values\n",
    "                    )\n",
    "                    \n",
    "                    result_dict = dict(zip(group_by_cols, group_vals if isinstance(group_vals, tuple) else [group_vals]))\n",
    "                    result_dict.update({\n",
    "                        'model1': model1,\n",
    "                        'model2': model2,\n",
    "                        'dm_stat': float(dm_stat),\n",
    "                        'p_value': float(p_val),\n",
    "                        'n_obs': len(data1_aligned),\n",
    "                        'significant': float(p_val) < 0.05\n",
    "                    })\n",
    "                    dm_results.append(result_dict)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in DM test for {model1} vs {model2}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(dm_results)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 13.5. Grid Search Enhancement (AÑADIR AQUÍ)\n",
    "# ------------------------------------------------\n",
    "def grid_search_model(X_train, y_train, X_val, y_val, model_type):\n",
    "    \"\"\"Enhanced grid search with multiple metrics - SAFE VERSION\"\"\"\n",
    "    try:\n",
    "        best_cfg, best_score = None, np.inf\n",
    "        search_results = []\n",
    "        \n",
    "        if model_type not in param_grid:\n",
    "            return None, np.inf\n",
    "        \n",
    "        # Limitar búsqueda para evitar timeouts\n",
    "        param_configs = list(ParameterGrid(param_grid[model_type]))\n",
    "        max_configs = min(6, len(param_configs))  # Máximo 6 configuraciones\n",
    "        \n",
    "        for i, cfg in enumerate(param_configs[:max_configs]):\n",
    "            try:\n",
    "                print(f\"    Grid search {i+1}/{max_configs} for {model_type}\")\n",
    "                \n",
    "                if model_type == 'ANN':\n",
    "                    m = build_model(model_type, X_train.shape[1:], \n",
    "                                  layers=cfg['layers'], lr=cfg['learning_rate'],\n",
    "                                  dropout_rate=cfg.get('dropout_rate', 0.2))\n",
    "                elif model_type in ['LSTM', 'GRU']:\n",
    "                    m = build_model(model_type, X_train.shape[1:], \n",
    "                                  layers=cfg['units'], lr=cfg['learning_rate'],\n",
    "                                  dropout_rate=cfg.get('dropout_rate', 0.2))\n",
    "                else:\n",
    "                    m = build_model(model_type, X_train.shape[1:], lr=cfg['learning_rate'])\n",
    "                \n",
    "                hist = m.fit(X_train, y_train, epochs=20, batch_size=cfg.get('batch_size', 64),  # Reducidas épocas\n",
    "                            validation_data=(X_val, y_val), verbose=0,\n",
    "                            callbacks=[EarlyStopping(patience=3, restore_best_weights=True)])  # Menos paciencia\n",
    "                \n",
    "                val_loss = min(hist.history['val_loss']) if hist.history['val_loss'] else np.inf\n",
    "                \n",
    "                search_results.append({\n",
    "                    'config': cfg,\n",
    "                    'val_loss': val_loss,\n",
    "                    'train_loss': hist.history['loss'][-1] if hist.history['loss'] else np.inf\n",
    "                })\n",
    "                \n",
    "                if val_loss < best_score:\n",
    "                    best_score = val_loss\n",
    "                    best_cfg = cfg\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in grid search for config {cfg}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_cfg, best_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Grid search failed for {model_type}: {e}\")\n",
    "        return None, np.inf\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 14. Enhanced Training & Evaluation (CORREGIDO)\n",
    "# ------------------------------------------------\n",
    "def train_and_evaluate_with_preds(idx, X, y, model_type, regimes=None, epochs=50, batch_size=64):\n",
    "    \"\"\"Enhanced training with regime analysis and interpretability - FIXED\"\"\"\n",
    "    try:\n",
    "        split = int(len(X) * 0.8)\n",
    "        X_tr, y_tr, X_te, y_te = X[:split], y[:split], X[split:], y[split:]\n",
    "        idx_te = idx[split:]\n",
    "        regimes_te = regimes[split:] if regimes else None\n",
    "        \n",
    "        # Initialize profiler\n",
    "        profiler = ModelLatencyProfiler()\n",
    "        \n",
    "        # Grid search for selected models\n",
    "        if model_type in param_grid:\n",
    "            cfg, _ = grid_search_model(X_tr, y_tr, X_te, y_te, model_type)\n",
    "            if cfg:\n",
    "                if model_type == 'ANN':\n",
    "                    model = build_model(model_type, X_tr.shape[1:], \n",
    "                                      layers=cfg['layers'], lr=cfg['learning_rate'],\n",
    "                                      dropout_rate=cfg.get('dropout_rate', 0.2))\n",
    "                    batch_size = cfg['batch_size']\n",
    "                elif model_type in ['LSTM', 'GRU']:\n",
    "                    model = build_model(model_type, X_tr.shape[1:], \n",
    "                                      layers=cfg['units'], lr=cfg['learning_rate'],\n",
    "                                      dropout_rate=cfg.get('dropout_rate', 0.2))\n",
    "                    batch_size = cfg.get('batch_size', 64)\n",
    "                else:\n",
    "                    model = build_model(model_type, X_tr.shape[1:], lr=cfg['learning_rate'])\n",
    "                    batch_size = cfg.get('batch_size', 64)\n",
    "            else:\n",
    "                model = build_model(model_type, X_tr.shape[1:])\n",
    "        else:\n",
    "            model = build_model(model_type, X_tr.shape[1:])\n",
    "        \n",
    "        # Training with callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),  # Reducida paciencia\n",
    "            ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            history = model.fit(X_tr, y_tr, epochs=epochs, batch_size=batch_size,\n",
    "                               verbose=0, validation_split=0.2, callbacks=callbacks)\n",
    "        except Exception as e:\n",
    "            print(f\"Training failed for {model_type}: {e}\")\n",
    "            # Return default values if training fails\n",
    "            return {\n",
    "                'mse': np.inf, 'rmse': np.inf, 'mae': np.inf, 'r2': -np.inf,\n",
    "                'explained_variance': -np.inf, 'mape': np.inf\n",
    "            }, pd.DataFrame()\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        try:\n",
    "            y_pred = model.predict(X_te, verbose=0).flatten()\n",
    "            mets = calculate_metrics(y_te, y_pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction failed for {model_type}: {e}\")\n",
    "            return {\n",
    "                'mse': np.inf, 'rmse': np.inf, 'mae': np.inf, 'r2': -np.inf,\n",
    "                'explained_variance': -np.inf, 'mape': np.inf\n",
    "            }, pd.DataFrame()\n",
    "        \n",
    "        # Measure inference latency\n",
    "        try:\n",
    "            latency_stats = profiler.measure_inference_time(model, X_te, model_type)\n",
    "            mets.update({f'latency_{k}': v for k, v in latency_stats.items() if k != 'model'})\n",
    "        except Exception as e:\n",
    "            print(f\"Latency measurement failed for {model_type}: {e}\")\n",
    "        \n",
    "        # Training metrics\n",
    "        mets['train_loss'] = history.history['loss'][-1] if history.history['loss'] else np.nan\n",
    "        mets['val_loss'] = history.history['val_loss'][-1] if 'val_loss' in history.history else np.nan\n",
    "        mets['epochs_trained'] = len(history.history['loss']) if history.history['loss'] else 0\n",
    "        \n",
    "        # Feature importance analysis - SOLO PARA MODELOS SIMPLES\n",
    "        try:\n",
    "            feature_names = [f'feature_{i}' for i in range(X_tr.shape[-1])]\n",
    "            \n",
    "            # Solo intentar SHAP para modelos simples y con datos suficientes\n",
    "            if model_type in ['ANN', 'Lightweight_ANN'] and X_te.shape[0] > 20:\n",
    "                importance_scores, shap_values = calculate_feature_importance_shap(model, X_te, feature_names)\n",
    "                if importance_scores is not None:\n",
    "                    visualize_feature_importance(importance_scores, feature_names, f\"{model_type}_Feature_Importance\")\n",
    "            else:\n",
    "                print(f\"Skipping SHAP analysis for {model_type} (too complex or insufficient data)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Feature importance analysis failed for {model_type}: {e}\")\n",
    "        \n",
    "        # Visualization - SIMPLIFICADA\n",
    "        try:\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Forecast plot - Solo primeros 100 puntos\n",
    "            plt.subplot(2, 2, 1)\n",
    "            n_plot = min(100, len(idx_te))\n",
    "            plt.plot(idx_te[:n_plot], y_te[:n_plot], label='True', alpha=0.7)\n",
    "            plt.plot(idx_te[:n_plot], y_pred[:n_plot], label='Pred', alpha=0.7)\n",
    "            plt.legend()\n",
    "            plt.title(f'{model_type} Forecast vs True')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            # Error distribution\n",
    "            plt.subplot(2, 2, 2)\n",
    "            errs = y_te - y_pred\n",
    "            plt.hist(errs, bins=30, alpha=0.7, edgecolor='black')\n",
    "            plt.title(f'{model_type} Error Distribution')\n",
    "            plt.xlabel('Prediction Error')\n",
    "            \n",
    "            # Loss curves\n",
    "            plt.subplot(2, 2, 3)\n",
    "            if 'loss' in history.history and history.history['loss']:\n",
    "                plt.plot(history.history['loss'], label='Train Loss')\n",
    "                if 'val_loss' in history.history and history.history['val_loss']:\n",
    "                    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "                plt.legend()\n",
    "            plt.title(f'{model_type} Loss Curves')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            \n",
    "            # Regime-specific performance if available\n",
    "            plt.subplot(2, 2, 4)\n",
    "            if regimes_te and len(set(regimes_te)) > 1:\n",
    "                regime_performance = {}\n",
    "                unique_regimes = list(set(regimes_te))\n",
    "                for regime in unique_regimes:\n",
    "                    regime_mask = [r == regime for r in regimes_te]\n",
    "                    if sum(regime_mask) > 0:\n",
    "                        regime_mse = mean_squared_error(\n",
    "                            np.array(y_te)[regime_mask], \n",
    "                            np.array(y_pred)[regime_mask]\n",
    "                        )\n",
    "                        regime_performance[regime] = regime_mse\n",
    "                \n",
    "                if regime_performance:\n",
    "                    plt.bar(regime_performance.keys(), regime_performance.values())\n",
    "                    plt.title(f'{model_type} MSE by Market Regime')\n",
    "                    plt.xticks(rotation=45)\n",
    "                    plt.ylabel('MSE')\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'No regime data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots/{model_type}_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Visualization failed for {model_type}: {e}\")\n",
    "            plt.close()\n",
    "        \n",
    "        # Create prediction dataframe with regime info\n",
    "        try:\n",
    "            pred_df = pd.DataFrame({\n",
    "                'time_index': idx_te,\n",
    "                'y_true': y_te,\n",
    "                'y_pred': y_pred\n",
    "            })\n",
    "            \n",
    "            if regimes_te:\n",
    "                pred_df['regime'] = regimes_te\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"DataFrame creation failed for {model_type}: {e}\")\n",
    "            pred_df = pd.DataFrame()\n",
    "        \n",
    "        return mets, pred_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Overall training failed for {model_type}: {e}\")\n",
    "        return {\n",
    "            'mse': np.inf, 'rmse': np.inf, 'mae': np.inf, 'r2': -np.inf,\n",
    "            'explained_variance': -np.inf, 'mape': np.inf\n",
    "        }, pd.DataFrame()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 15. Enhanced Benchmark Function (PARTE CORREGIDA)\n",
    "# ------------------------------------------------\n",
    "# ------------------------------------------------\n",
    "# 15. Enhanced Benchmark Function (ARREGLO DEL ÍNDICE)\n",
    "# ------------------------------------------------\n",
    "def benchmark_all_combinations():\n",
    "    \"\"\"Enhanced benchmarking with comprehensive analysis - FIXED INDEX ERROR\"\"\"\n",
    "    base_cols = ['DIX','GEX','SKEW','PUTCALLRATIO']\n",
    "    models = ['ARIMA','GARCH','ANN','RNN','LSTM','GRU','CNN','CNN_LSTM','CapsNet',\n",
    "              'Lightweight_ANN', 'Lightweight_LSTM', 'Lightweight_CNN_LSTM']\n",
    "    \n",
    "    all_preds = []\n",
    "    results = []\n",
    "    \n",
    "    df0 = load_data(r'C:\\Users\\antonio-jose.martine\\OneDrive - GFI\\Documentos\\Doctorado\\articulo 8 peer review\\Data\\merged_market_data_vix.csv')\n",
    "    \n",
    "    print(\"Performing feature selection analysis...\")\n",
    "    \n",
    "    for r in range(1, len(base_cols)+1):\n",
    "        for combo in itertools.combinations(base_cols, r):\n",
    "            print(f\"Processing feature combination: {combo}\")\n",
    "            \n",
    "            for fractal in ['none','hurst','wavelet']:\n",
    "                df = df0.copy()\n",
    "                \n",
    "                # Apply fractal/wavelet features\n",
    "                if fractal == 'hurst':\n",
    "                    df = apply_hurst(df)\n",
    "                if fractal == 'wavelet':\n",
    "                    df, _ = apply_wavelets(df)\n",
    "                \n",
    "                # Prepare feature list\n",
    "                feats = list(combo)\n",
    "                if fractal == 'hurst':\n",
    "                    feats += ['HURST_PRICE']\n",
    "                if fractal == 'wavelet':\n",
    "                    feats += [c for c in df.columns if c.startswith('WAVELET_')]\n",
    "                \n",
    "                # Clean data\n",
    "                df_clean = df.dropna(subset=feats+['VIX']).copy()\n",
    "                \n",
    "                if len(df_clean) < 50:  # Minimum data requirement\n",
    "                    print(f\"Not enough data for {combo}, {fractal}\")\n",
    "                    continue\n",
    "                \n",
    "                # Train and evaluate models\n",
    "                for model_name in models:\n",
    "                    print(f\"  Training {model_name}...\")\n",
    "                    \n",
    "                    try:\n",
    "                        if model_name == 'ARIMA':\n",
    "                            # ARIMA entrenamiento corregido\n",
    "                            series = df_clean['VIX'].reset_index(drop=True)\n",
    "                            split = int(len(series) * 0.8)\n",
    "                            \n",
    "                            train_series = series[:split]\n",
    "                            test_series = series[split:]\n",
    "                            \n",
    "                            m_ar = train_arima_baseline(train_series)\n",
    "                            \n",
    "                            if m_ar is not None:\n",
    "                                forecast_steps = len(test_series)\n",
    "                                pred = m_ar.forecast(steps=forecast_steps)\n",
    "                                \n",
    "                                if len(pred) == len(test_series):\n",
    "                                    mets = calculate_metrics(test_series.values, pred.values)\n",
    "                                    \n",
    "                                    test_dates = df_clean.index[split:split+len(test_series)]\n",
    "                                    \n",
    "                                    pred_df = pd.DataFrame({\n",
    "                                        'time_index': test_dates,\n",
    "                                        'y_true': test_series.values,\n",
    "                                        'y_pred': pred.values\n",
    "                                    })\n",
    "                                else:\n",
    "                                    print(f\"ARIMA forecast length mismatch: {len(pred)} vs {len(test_series)}\")\n",
    "                                    continue\n",
    "                            else:\n",
    "                                print(\"ARIMA training failed, skipping...\")\n",
    "                                continue\n",
    "                                \n",
    "                        elif model_name == 'GARCH':\n",
    "                            # GARCH entrenamiento corregido\n",
    "                            series = df_clean['VIX'].reset_index(drop=True)\n",
    "                            split = int(len(series) * 0.8)\n",
    "                            \n",
    "                            train_series = series[:split]\n",
    "                            test_series = series[split:]\n",
    "                            \n",
    "                            m_g = train_garch_baseline(train_series)\n",
    "                            \n",
    "                            if m_g is not None:\n",
    "                                forecast_steps = len(test_series)\n",
    "                                try:\n",
    "                                    fore = m_g.forecast(horizon=forecast_steps, reindex=False)\n",
    "                                    vol_pred = np.sqrt(fore.variance.values.flatten())\n",
    "                                    \n",
    "                                    if len(vol_pred) == 1:\n",
    "                                        vol_pred = np.full(forecast_steps, vol_pred[0])\n",
    "                                    elif len(vol_pred) != forecast_steps:\n",
    "                                        vol_pred = np.full(forecast_steps, vol_pred[-1])\n",
    "                                    \n",
    "                                    mets = calculate_metrics(test_series.values, vol_pred)\n",
    "                                    \n",
    "                                    test_dates = df_clean.index[split:split+len(test_series)]\n",
    "                                    \n",
    "                                    pred_df = pd.DataFrame({\n",
    "                                        'time_index': test_dates,\n",
    "                                        'y_true': test_series.values,\n",
    "                                        'y_pred': vol_pred\n",
    "                                    })\n",
    "                                except Exception as e:\n",
    "                                    print(f\"GARCH forecasting failed: {e}\")\n",
    "                                    continue\n",
    "                            else:\n",
    "                                print(\"GARCH training failed, skipping...\")\n",
    "                                continue\n",
    "                            \n",
    "                        else:\n",
    "                            # Neural network models - FIXED INDEX ISSUE\n",
    "                            df_clean_nn = df_clean.copy()\n",
    "                            \n",
    "                            # CRITICAL FIX: Check if already has numeric index\n",
    "                            if 'level_0' in df_clean_nn.columns:\n",
    "                                df_clean_nn = df_clean_nn.drop('level_0', axis=1)\n",
    "                            \n",
    "                            # Only reset index if DATE is still the index\n",
    "                            if df_clean_nn.index.name == 'DATE' or isinstance(df_clean_nn.index, pd.DatetimeIndex):\n",
    "                                df_clean_nn.reset_index(inplace=True)\n",
    "                            \n",
    "                            X, y, idx, scaler, regimes = prepare_features(df_clean_nn, feats, 'VIX')\n",
    "                            if X is None:\n",
    "                                continue\n",
    "                                \n",
    "                            mets, pred_df = train_and_evaluate_with_preds(\n",
    "                                idx, X, y, model_name, regimes\n",
    "                            )\n",
    "                        \n",
    "                        # Store results - SAME FOR ALL MODELS\n",
    "                        result_entry = {\n",
    "                            'features': '+'.join(combo),\n",
    "                            'model': model_name,\n",
    "                            'fractal': fractal,\n",
    "                            **mets\n",
    "                        }\n",
    "                        results.append(result_entry)\n",
    "                        \n",
    "                        # Add metadata to predictions\n",
    "                        pred_df = pred_df.assign(\n",
    "                            features='+'.join(combo),\n",
    "                            model=model_name,\n",
    "                            fractal=fractal\n",
    "                        )\n",
    "                        all_preds.extend(pred_df.to_dict('records'))\n",
    "                        \n",
    "                        print(f\"    {model_name} completed - R2: {mets.get('r2', 'N/A'):.3f}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error training {model_name}: {e}\")\n",
    "                        continue\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('results/combo_results_enhanced.csv', index=False)\n",
    "    \n",
    "    all_preds_df = pd.DataFrame(all_preds)\n",
    "    \n",
    "    # Enhanced DM tests\n",
    "    print(\"Performing Diebold-Mariano tests...\")\n",
    "    dm_df = compare_models_dm(all_preds_df, ['features','fractal'])\n",
    "    dm_df.to_csv('results/dm_results_enhanced.csv', index=False)\n",
    "    \n",
    "    # Market shock analysis\n",
    "    print(\"Analyzing market shock scenarios...\")\n",
    "    shock_analysis_df = analyze_market_shock_scenarios(all_preds_df)\n",
    "    shock_analysis_df.to_csv('results/shock_analysis.csv', index=False)\n",
    "    \n",
    "    print(\"Enhanced benchmark analysis complete!\")\n",
    "    return results_df, all_preds_df, dm_df, shock_analysis_df\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 16. Main execution\n",
    "# ------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting enhanced benchmark analysis...\")\n",
    "    results_df, preds_df, dm_df, shock_df = benchmark_all_combinations()\n",
    "    gc.collect()\n",
    "    print(\"Analysis complete. Results saved to 'results/' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
